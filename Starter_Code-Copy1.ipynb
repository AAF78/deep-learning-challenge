{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.11.*\n",
      "  Downloading tensorflow-2.11.0-cp37-cp37m-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.11.0; platform_system == \"Windows\"\n",
      "  Downloading tensorflow_intel-2.11.0-cp37-cp37m-win_amd64.whl (266.3 MB)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\msfte\\anaconda3\\envs\\pythondata\\lib\\site-packages (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow==2.11.*) (0.4.0)\n",
      "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
      "  Using cached tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "Collecting tensorboard<2.12,>=2.11\n",
      "  Using cached tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\msfte\\anaconda3\\envs\\pythondata\\lib\\site-packages (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow==2.11.*) (3.19.6)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\msfte\\anaconda3\\envs\\pythondata\\lib\\site-packages (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow==2.11.*) (1.14.1)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\msfte\\anaconda3\\envs\\pythondata\\lib\\site-packages (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow==2.11.*) (22.10.26)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1; platform_machine != \"arm64\" or platform_system != \"Darwin\" in c:\\users\\msfte\\anaconda3\\envs\\pythondata\\lib\\site-packages (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow==2.11.*) (0.27.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\msfte\\anaconda3\\envs\\pythondata\\lib\\site-packages (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow==2.11.*) (14.0.6)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\msfte\\anaconda3\\envs\\pythondata\\lib\\site-packages (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow==2.11.*) (1.21.6)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\msfte\\anaconda3\\envs\\pythondata\\lib\\site-packages (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow==2.11.*) (2.1.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\msfte\\anaconda3\\envs\\pythondata\\lib\\site-packages (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow==2.11.*) (3.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\msfte\\anaconda3\\envs\\pythondata\\lib\\site-packages (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow==2.11.*) (4.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\msfte\\anaconda3\\envs\\pythondata\\lib\\site-packages (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow==2.11.*) (3.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\msfte\\anaconda3\\envs\\pythondata\\lib\\site-packages (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow==2.11.*) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\msfte\\anaconda3\\envs\\pythondata\\lib\\site-packages (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow==2.11.*) (1.50.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\msfte\\anaconda3\\envs\\pythondata\\lib\\site-packages (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow==2.11.*) (1.6.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\msfte\\anaconda3\\envs\\pythondata\\lib\\site-packages (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow==2.11.*) (21.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\msfte\\anaconda3\\envs\\pythondata\\lib\\site-packages (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow==2.11.*) (47.3.1.post20200622)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\msfte\\anaconda3\\envs\\pythondata\\lib\\site-packages (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow==2.11.*) (1.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\msfte\\anaconda3\\envs\\pythondata\\lib\\site-packages (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow==2.11.*) (1.3.0)\n",
      "Collecting keras<2.12,>=2.11.0\n",
      "  Using cached keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\msfte\\anaconda3\\envs\\pythondata\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow==2.11.*) (2.27.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\msfte\\anaconda3\\envs\\pythondata\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow==2.11.*) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\msfte\\anaconda3\\envs\\pythondata\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow==2.11.*) (2.2.2)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\msfte\\anaconda3\\envs\\pythondata\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow==2.11.*) (0.34.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\msfte\\anaconda3\\envs\\pythondata\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow==2.11.*) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\msfte\\anaconda3\\envs\\pythondata\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow==2.11.*) (3.4.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\msfte\\anaconda3\\envs\\pythondata\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow==2.11.*) (2.14.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\msfte\\anaconda3\\envs\\pythondata\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow==2.11.*) (0.6.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\msfte\\anaconda3\\envs\\pythondata\\lib\\site-packages (from packaging->tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow==2.11.*) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\msfte\\anaconda3\\envs\\pythondata\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow==2.11.*) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in c:\\users\\msfte\\anaconda3\\envs\\pythondata\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow==2.11.*) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in c:\\users\\msfte\\anaconda3\\envs\\pythondata\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow==2.11.*) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\msfte\\anaconda3\\envs\\pythondata\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow==2.11.*) (1.26.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\msfte\\anaconda3\\envs\\pythondata\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow==2.11.*) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\msfte\\anaconda3\\envs\\pythondata\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow==2.11.*) (2.1.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in c:\\users\\msfte\\anaconda3\\envs\\pythondata\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow==2.11.*) (4.11.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in c:\\users\\msfte\\anaconda3\\envs\\pythondata\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow==2.11.*) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\msfte\\anaconda3\\envs\\pythondata\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow==2.11.*) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\msfte\\anaconda3\\envs\\pythondata\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow==2.11.*) (5.2.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\msfte\\anaconda3\\envs\\pythondata\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow==2.11.*) (3.2.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\msfte\\anaconda3\\envs\\pythondata\\lib\\site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow==2.11.*) (3.7.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\msfte\\anaconda3\\envs\\pythondata\\lib\\site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow==2.11.*) (0.4.8)\n",
      "Installing collected packages: tensorflow-estimator, tensorboard, keras, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.10.0\n",
      "    Uninstalling tensorflow-estimator-2.10.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.10.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.10.1\n",
      "    Uninstalling tensorboard-2.10.1:\n",
      "      Successfully uninstalled tensorboard-2.10.1\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.10.0\n",
      "    Uninstalling keras-2.10.0:\n",
      "      Successfully uninstalled keras-2.10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an EnvironmentError: [WinError 5] Access is denied: 'C:\\\\Users\\\\msfte\\\\anaconda3\\\\envs\\\\PythonData\\\\Lib\\\\site-packages\\\\tensorflow\\\\compiler\\\\tf2tensorrt\\\\_pywrap_py_utils.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.11.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python.eager.polymorphic_function'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21716\\1942568711.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#  Import and read the charity_data.csv.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackprop\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGradientTape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolymorphic_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolymorphic_function\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant_op\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_spec\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDeviceSpecV2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mDeviceSpec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python.eager.polymorphic_function'"
     ]
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "#  Import and read the charity_data.csv.\n",
    "import pandas as pd \n",
    "application_df = pd.read_csv(\"Resources/charity_data.csv\")\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
    "appl_df = application_df.drop(['EIN', 'NAME'], axis=1)\n",
    "appl_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Determine the number of unique values in each column.\n",
    "appl_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at APPLICATION_TYPE value counts for binning\n",
    "app_ct = appl_df['APPLICATION_TYPE'].value_counts()\n",
    "app_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a cutoff value and create a list of application types to be replaced\n",
    "# use the variable name `application_types_to_replace`\n",
    "application_types_to_replace = list(app_ct[app_ct < 500].index)\n",
    "\n",
    "# Replace in dataframe\n",
    "for app in application_types_to_replace:\n",
    "    appl_df['APPLICATION_TYPE'] = appl_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
    "\n",
    "# Check to make sure binning was successful\n",
    "appl_df['APPLICATION_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at CLASSIFICATION value counts for binning\n",
    "class_ct = appl_df['CLASSIFICATION'].value_counts()\n",
    "class_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may find it helpful to look at CLASSIFICATION value counts >1\n",
    "#class_ct = appl_df['CLASSIFICATION'].value_counts(counts > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a cutoff value and create a list of classifications to be replaced\n",
    "# use the variable name `classifications_to_replace`\n",
    "classifications_to_replace = list(class_ct[class_ct < 250].index)\n",
    "\n",
    "# Replace in dataframe\n",
    "for cls in classifications_to_replace:\n",
    "    appl_df['CLASSIFICATION'] = appl_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
    "    \n",
    "# Check to make sure binning was successful\n",
    "appl_df['CLASSIFICATION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical data to numeric with `pd.get_dummies`\n",
    "charity_numbers = pd.get_dummies(appl_df)\n",
    "charity_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = charity_numbers['IS_SUCCESSFUL']\n",
    "X = charity_numbers.drop(['IS_SUCCESSFUL'], axis=1)\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import an Adaptive Boosting classifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = AdaBoostClassifier(random_state=1).fit(X_train_scaled, y_train)\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f'Training Score: {clf.score(X_train_scaled, y_train)}')\n",
    "print(f'Testing Score: {clf.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile, Train and Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I adjusted the hidden layers a few times, from 2 layers @ 8/16, to 3 layers 11/15/22. The additional layers produced a better outcome in terms of accuracy, but still not the 75% I hoped for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 =  11\n",
    "hidden_nodes_layer2 = 15\n",
    "hidden_nodes_layer3 = 22\n",
    "\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn_model.add(tf.keras.layers.Dense(hidden_nodes_layer1, activation=\"relu\", input_dim=45))\n",
    "\n",
    "# Second hidden layer\n",
    "nn_model.add(tf.keras.layers.Dense(hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn_model.add(tf.keras.layers.Dense(hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tf-nightly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I attempted to use the Adadelta and AdamW optimization here as well; I wanted to address weight decay and both do this. However, the AdamW is experimental and when I pipinstalled the module for applying this optimization, it gave me an error that wasn't resolvable. When I attempted the Adadelta optimizer, the model immediately fit to a 0.5592 loss: 0.7433 accuracy throughout every single epoch, which clearly wasn't the expected outcome, so I discarded that optimize and went back to the Adam optimizer instead. ML is iterative and requires a considerable amount of trial-and-error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, I have attempted to adjust the epochs 5 times: 50, 100, 200, 300, 250. 200 is probably optimal; anything above this seems to create decay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export our model to HDF5 file\n",
    "nn_model.save('AlphabetSoupCharityboosted.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save charity_numbers as a .csv\n",
    "charity_numbers.to_csv('charity_numbers_boosted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
